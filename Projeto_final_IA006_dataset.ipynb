{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernanda/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display as ld\n",
    "# Printa todos os valores do array\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(threshold=10)\n",
    "import pandas as pd\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import os\n",
    "import re\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = glob.glob('1seg/test/*.mp3')\n",
    "#data = glob.glob('2seg/fold1/*.mp3')\n",
    "#data = glob.glob('../../Projeto_phd/academia/*.wav')\n",
    "data_casa = glob.glob('casa/*.wav')\n",
    "data_academia = glob.glob('academia/*.wav')\n",
    "#data_faculdade = glob.glob('faculdade/*.wav')\n",
    "#print ((data_casa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datas(data):\n",
    "    len_audios = []\n",
    "    audios = []\n",
    "\n",
    "    for file in sorted(data):\n",
    "        audio, sr = librosa.core.load(file, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        len_audios.append(len(audio))\n",
    "        audios.append(audio)\n",
    "        max_audio = max(len_audios)\n",
    "        \n",
    "    return audios, max(len_audios), sr\n",
    "\n",
    "def spectrograms(audios, len_audios, sr):\n",
    "    \n",
    "    hop_length = 400\n",
    "    n_fft = 500\n",
    "\n",
    "    #To convert the hop length and frame size to units of seconds:\n",
    "    #print (\"hop length[s]:\", float(hop_length)/sr) # units of seconds\n",
    "    #print (\"frame size[s]:\",float(n_fft)/sr) # units of seconds\n",
    "\n",
    "    audios_resize = []\n",
    "    specs = []\n",
    "\n",
    "    for i in range(len(audios)):\n",
    "        shape = (len_audios)\n",
    "        i_audio = np.array(audios[i])\n",
    "        i_audio.resize(shape)\n",
    "        x = librosa.stft(i_audio, n_fft=n_fft, hop_length=hop_length)\n",
    "        X = librosa.amplitude_to_db(np.abs(x), ref=np.max)\n",
    "        specs.append(X)\n",
    "        audios_resize.append(i_audio)\n",
    "        \n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67356 56905\n",
      "(251, 169)\n",
      "(251, 169)\n"
     ]
    }
   ],
   "source": [
    "audios_a, len_audios_a, sr = load_datas(data_academia)\n",
    "audios_c, len_audios_c, sr = load_datas(data_casa)\n",
    "#audios_f, len_audios_f, sr = load_datas(data_faculdade)\n",
    "\n",
    "print(len_audios_a, len_audios_c)\n",
    "\n",
    "def spectro_length(audio1, len1, audio2, len2, sr):\n",
    "    \n",
    "    if len1 > len2:\n",
    "        specs1 = spectrograms(audio1, len1, sr)\n",
    "        specs2 = spectrograms(audio2, len1, sr)\n",
    "    else:\n",
    "        specs1 = spectrograms(audio1, len2, sr)\n",
    "        specs2 = spectrograms(audio2, len2, sr)\n",
    "    return specs1, specs2\n",
    "\n",
    "specs_a, specs_c = spectro_length(audios_a, len_audios_a, audios_c, len_audios_c, sr)\n",
    "\n",
    "print (specs_a[0].shape)\n",
    "print (specs_c[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(pathname):\n",
    "    l = []\n",
    "    for file in pathname:\n",
    "        (dirname, sname) = os.path.split(file)\n",
    "        (name, ext) = os.path.splitext(sname)\n",
    "        #print (name)\n",
    "        n = re.split('[0-9]+', name, flags=re.IGNORECASE)\n",
    "        l.append([n[0]])\n",
    "    return l\n",
    "\n",
    "#l_casa = np.array(labeling(data_casa))\n",
    "l_casa = labeling(data_casa)\n",
    "l_academia = labeling(data_academia)\n",
    "\n",
    "#type(l_casa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test1, y_train, y_test1 = train_test_split(specs_c, l_casa, test_size=0.5, random_state=42, stratify=l_casa)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test1, y_test1, test_size=0.5, random_state=42, stratify=y_train1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To separate 80% to train and 20% to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratify: certifica a mesma quantidade de audios de cada classe.\n",
    "\n",
    "def holdout(data1, l1, data2, l2):\n",
    "    \n",
    "    x_train1, x_test, y_train1, y_test = train_test_split(data1, l1, test_size=0.5, random_state=42, stratify=l1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, test_size=0.8, random_state=42, stratify=y_train1)\n",
    "    \n",
    "    X_train1, X_test, Y_train1, Y_test = train_test_split(data2, l2, test_size=0.5, random_state=42, stratify=l2)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train1, Y_train1, test_size=0.8, random_state=42, stratify=Y_train1)\n",
    "    \n",
    "    #x_tr = np.concatenate(x_train, X_train)\n",
    "    #x_v = np.concatenate(x_val, X_val)\n",
    "    #x_te = np.concatenate(x_test, X_test)\n",
    "    \n",
    "    x_tr = x_train + X_train\n",
    "    x_v = x_val + X_val\n",
    "    x_te = x_test + X_test\n",
    "    \n",
    "    y_tr = y_train + Y_train\n",
    "    y_v = y_val + Y_val\n",
    "    y_te = y_test + Y_test\n",
    "    \n",
    "    return x_tr, x_v, x_te, y_tr, y_v, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = holdout(specs_a, l_academia, specs_c,l_casa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 320, 400)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (type(y_train))\n",
    "x_train_np = np.array(x_train)\n",
    "x_test_np = np.array(x_test)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np = np.array(y_test)\n",
    "y_val_np = np.array(y_val)\n",
    "x_val_np = np.array(x_val)\n",
    "#print (y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(x_train_np, \"features_propaganda/2segs/x_train.pkl\")\n",
    "joblib.dump(x_test_np, \"features_propaganda/2segs/x_test.pkl\")\n",
    "joblib.dump(x_val_np, \"features_propaganda/2segs/x_val.pkl\")\n",
    "joblib.dump(y_train_np, \"features_propaganda/2segs/y_train.pkl\")\n",
    "joblib.dump(y_test_np, \"features_propaganda/2segs/y_test.pkl\")\n",
    "joblib.dump(y_val_np, \"features_propaganda/2segs/y_val.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
